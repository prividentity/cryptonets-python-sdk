{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import json\n",
    "import pathlib\n",
    "import sys\n",
    "from ctypes import *\n",
    "from typing import Any\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "class NativeMethods(object):\n",
    "    def __init__(self, api_key: str, server_url: str, local_storage_path: str,\n",
    "                 logging_level=3, tf_num_thread=0, config_object= None):\n",
    "        try:\n",
    "            self._config_object = config_object\n",
    "            self._library_path = '.lib/lib_fhe.so'\n",
    "            self._spl_so_face = None\n",
    "            self._tf_num_thread = tf_num_thread\n",
    "            self._api_key = bytes(api_key, 'utf-8')\n",
    "            self._server_url = bytes(server_url, 'utf-8')\n",
    "            self._local_storage_path = bytes(local_storage_path, 'utf-8')\n",
    "            self._logging_level = logging_level\n",
    "            self._face_setup()\n",
    "        except Exception as e:\n",
    "            print(\"Error \", e)\n",
    "            sys.exit(1)\n",
    "\n",
    "    def update_config(self, config_object):\n",
    "        self._config_object = config_object\n",
    "        if self._config_object and self._config_object.get_config_param():\n",
    "            c_config_param = c_char_p(bytes(self._config_object.get_config_param(), 'utf-8'))\n",
    "            c_config_param_len = c_int(len(self._config_object.get_config_param()))\n",
    "            self._spl_so_face.privid_set_configuration(self._spl_so_face.new_handle, c_config_param, c_config_param_len)\n",
    "\n",
    "    def _face_setup(self):\n",
    "        self._spl_so_face = ctypes.CDLL(self._library_path)\n",
    "\n",
    "        # privid_global_settings\n",
    "        self._spl_so_face.privid_global_settings.argtypes = [c_uint8, c_uint8]\n",
    "        self._spl_so_face.privid_global_settings.restype = c_bool\n",
    "        self._spl_so_face.privid_global_settings(0, self._logging_level)\n",
    "\n",
    "        # FHE_init\n",
    "        # self._spl_so_face._FHE_init = self._spl_so_face.FHE_init\n",
    "        self._spl_so_face.FHE_init.argtypes = [c_int]\n",
    "        self._spl_so_face.FHE_init.restype = POINTER(c_uint8)\n",
    "        self._spl_so_face.handle = self._spl_so_face.FHE_init(self._logging_level)\n",
    "\n",
    "        self._spl_so_face.privid_initialize_session_join.argtypes = [POINTER(c_void_p), c_void_p]\n",
    "        self._spl_so_face.privid_initialize_session_join.restype = c_bool\n",
    "        self._spl_so_face.new_handle = c_void_p()\n",
    "\n",
    "        self._spl_so_face.privid_initialize_session_join(byref(self._spl_so_face.new_handle), self._spl_so_face.handle)\n",
    "\n",
    "        # FHE_configure_url\n",
    "        # self._spl_so_face.FHE_configure_url = self._spl_so_face.FHE_configure_url\n",
    "        self._spl_so_face.FHE_configure_url.argtypes = [\n",
    "            POINTER(c_uint8), c_int, c_char_p, c_int]\n",
    "        self._spl_so_face.FHE_configure_url.restype = c_uint8\n",
    "\n",
    "        # _FHE_configure_local_storage_dir_name self._spl_so_face.FHE_configure_local_storage_dir_name =\n",
    "        # self._spl_so_face.FHE_configure_local_storage_dir_name\n",
    "#         self._spl_so_face.FHE_configure_local_storage_dir_name.argtypes = [\n",
    "#             c_char_p, c_int]\n",
    "#         self._spl_so_face.FHE_configure_local_storage_dir_name.restype = c_uint8\n",
    "        # privid_set_configuration\n",
    "        self._spl_so_face.privid_set_configuration.argtypes = [c_void_p, c_char_p, c_int]\n",
    "        self._spl_so_face.privid_set_configuration.restype = c_bool\n",
    "\n",
    "        # configure_url , API key and storage location\n",
    "        self._spl_so_face.FHE_configure_url(self._spl_so_face.handle, c_int32(46),\n",
    "                                            c_char_p(self._api_key),\n",
    "                                            c_int32(len(self._api_key)))\n",
    "\n",
    "        self._spl_so_face.FHE_configure_url(self._spl_so_face.handle, c_int32(42),\n",
    "                                            c_char_p(self._server_url),\n",
    "                                            c_int32(len(self._server_url)))\n",
    "\n",
    "#         self._spl_so_face.FHE_configure_local_storage_dir_name(c_char_p(self._local_storage_path),\n",
    "#                                                                c_int32(len(self._local_storage_path)))\n",
    "\n",
    "#         cache_config = json.dumps({ \"cache_type\": \"nocache\"})\n",
    "#         c_config_param = c_char_p(bytes(cache_config, 'utf-8'))\n",
    "#         c_config_param_len = c_int(len(cache_config))\n",
    "#         self._spl_so_face.privid_set_configuration(self._spl_so_face.new_handle, c_config_param, c_config_param_len)\n",
    "\n",
    "        # Configure parameters \n",
    "        if self._config_object and self._config_object.get_config_param():\n",
    "            c_config_param = c_char_p(bytes(self._config_object.get_config_param(), 'utf-8'))\n",
    "            c_config_param_len = c_int(len(self._config_object.get_config_param()))\n",
    "            self._spl_so_face.privid_set_configuration(self._spl_so_face.new_handle, c_config_param, c_config_param_len)\n",
    "    \n",
    "        # FHE_close\n",
    "        # self._spl_so_face.FHE_close = self._spl_so_face.FHE_close\n",
    "        self._spl_so_face.FHE_close.argtypes = [POINTER(c_uint8)]\n",
    "        self._spl_so_face.FHE_close.restype = c_int\n",
    "\n",
    "        # privid_enroll_onefa\n",
    "        # self._spl_so_face.privid_enroll_onefa = self._spl_so_face.privid_enroll_onefa\n",
    "        self._spl_so_face.privid_enroll_onefa.argtypes = [c_void_p, c_char_p, c_int, POINTER(\n",
    "            c_uint8), c_int, c_int, c_int, c_int, POINTER(c_float), POINTER(c_int), c_bool, POINTER(c_uint8),\n",
    "                                                          POINTER(c_int), POINTER(c_char_p),\n",
    "                                                          POINTER(c_int)]\n",
    "        self._spl_so_face.privid_enroll_onefa.restype = c_int\n",
    "\n",
    "        # privid_face_predict_onefa\n",
    "        # self._spl_so_face.privid_face_predict_onefa = self._spl_so_face.privid_face_predict_onefa\n",
    "        self._spl_so_face.privid_face_predict_onefa.argtypes = [c_void_p, c_char_p, c_int, POINTER(\n",
    "            c_uint8), c_int, c_int, c_int, c_int, POINTER(c_float), POINTER(c_int), c_bool, POINTER(c_uint8),\n",
    "                                                                POINTER(c_int), POINTER(c_char_p),\n",
    "                                                                POINTER(c_int)]\n",
    "        self._spl_so_face.privid_face_predict_onefa.restype = c_int\n",
    "\n",
    "        # is_valid\n",
    "        # self._spl_so_face.is_valid = self._spl_so_face.is_valid\n",
    "        self._spl_so_face.is_valid.argtypes = [POINTER(c_uint8), c_bool, POINTER(\n",
    "            c_uint8), c_int, c_int, POINTER(c_uint8), POINTER(c_int), POINTER(c_char_p), POINTER(c_int),\n",
    "                                               POINTER(c_char_p), c_int]\n",
    "        self._spl_so_face.is_valid.restype = c_int\n",
    "\n",
    "        # FHE_delete\n",
    "        # self._spl_so_face.privid_user_delete = self._spl_so_face.privid_user_delete\n",
    "        self._spl_so_face.privid_user_delete.argtypes = [c_void_p, POINTER(c_char), c_int, POINTER(\n",
    "            c_char), c_int, POINTER(c_char_p), POINTER(c_int)]\n",
    "        self._spl_so_face.privid_user_delete.restype = c_int\n",
    "\n",
    "        # FHE_free_api_memory\n",
    "        # self._spl_so_face.FHE_free_api_memory = self._spl_so_face.FHE_free_api_memory\n",
    "        self._spl_so_face.FHE_free_api_memory.argtypes = [POINTER(c_char_p)]\n",
    "\n",
    "        # FHE_compare_files\n",
    "        # self._spl_so_face.privid_face_compare_files = self._spl_so_face.privid_face_compare_files\n",
    "        self._spl_so_face.privid_face_compare_files.argtypes = [c_void_p, c_float, c_char_p, c_int,\n",
    "                                                                POINTER(c_uint8), c_int, c_int, c_int,\n",
    "                                                                POINTER(c_uint8), c_int, c_int, c_int,\n",
    "                                                                POINTER(c_char_p),\n",
    "                                                                POINTER(c_int)]\n",
    "        self._spl_so_face.privid_face_compare_files.restype = c_int\n",
    "\n",
    "        # privid_validate\n",
    "        self._spl_so_face.privid_validate.argtypes = [\n",
    "            c_void_p, POINTER(c_uint8), c_int, c_int,\n",
    "            c_char_p, c_int, POINTER(c_char_p), POINTER(c_int)]\n",
    "        self._spl_so_face.privid_validate.restype = c_bool\n",
    "\n",
    "        # privid_estimate_age\n",
    "        self._spl_so_face.privid_estimate_age.argtypes = [\n",
    "            c_void_p, POINTER(c_uint8), c_int, c_int,\n",
    "            c_char_p, c_int, POINTER(c_char_p), POINTER(c_int)]\n",
    "        self._spl_so_face.privid_estimate_age.restype = c_bool\n",
    "\n",
    "        # privid_doc_scan_face\n",
    "        self._spl_so_face.privid_doc_scan_face.argtypes = [\n",
    "            c_void_p, c_char_p, c_int, POINTER(c_uint8), c_int, c_int,\n",
    "            POINTER(POINTER(c_uint8)), POINTER(c_int), POINTER(POINTER(c_uint8)), POINTER(c_int), \n",
    "            POINTER(c_char_p), POINTER(c_int)]\n",
    "        self._spl_so_face.privid_doc_scan_face.restype = c_int\n",
    "\n",
    "        # privid_doc_scan_barcode\n",
    "        self._spl_so_face.privid_doc_scan_barcode.argtypes = [\n",
    "            c_void_p, c_char_p, c_int, POINTER(c_uint8), c_int, c_int,\n",
    "            POINTER(POINTER(c_uint8)), POINTER(c_int), POINTER(POINTER(c_uint8)), POINTER(c_int), \n",
    "            POINTER(c_char_p), POINTER(c_int)]\n",
    "        self._spl_so_face.privid_doc_scan_barcode.restype = c_int\n",
    "\n",
    "\n",
    "    def doc_scan_barcode(self, image_data: np.array, config_object=None) -> Any:\n",
    "        try:\n",
    "            img = image_data\n",
    "            im_width = img.shape[1]\n",
    "            im_height = img.shape[0]\n",
    "\n",
    "            p_buffer_images_in = img.flatten()\n",
    "            c_p_buffer_images_in = p_buffer_images_in.ctypes.data_as(POINTER(c_uint8))\n",
    "\n",
    "            c_result = c_char_p()\n",
    "            c_result_len = c_int()\n",
    "            c_cropped_doc = pointer(c_uint8())\n",
    "            c_cropped_doc_len = c_int()\n",
    "            c_cropped_barcode = pointer(c_uint8())\n",
    "            c_cropped_barcode_len = c_int()\n",
    "            if config_object and config_object.get_config_param():\n",
    "                c_config_param = c_char_p(bytes(config_object.get_config_param(), 'utf-8'))\n",
    "                c_config_param_len = c_int(len(config_object.get_config_param()))\n",
    "            else:\n",
    "                c_config_param = c_char_p(bytes(\"\", 'utf-8'))\n",
    "                c_config_param_len = c_int(0)\n",
    "            self._spl_so_face.privid_doc_scan_barcode(\n",
    "                self._spl_so_face.new_handle, c_config_param, c_config_param_len,\n",
    "                c_p_buffer_images_in, c_int(im_width), c_int(im_height),\n",
    "                byref(c_cropped_doc), byref(c_cropped_doc_len),\n",
    "                byref(c_cropped_barcode), byref(c_cropped_barcode_len),\n",
    "                byref(c_result), byref(c_result_len))\n",
    "            \n",
    "            if not c_result.value or not c_result_len.value:\n",
    "                raise Exception(\"Something went wrong. Couldn't process the image for Doc API. \")\n",
    "            output_json = c_result.value[:c_result_len.value].decode()\n",
    "            self._spl_so_face.FHE_free_api_memory(c_result)\n",
    "            output_json = json.loads(output_json)\n",
    "            cropped_doc_bytes = c_cropped_doc[:c_cropped_doc_len.value]\n",
    "            output_json[\"c_crop_document\"] = Image.fromarray(np.uint8(np.reshape(cropped_doc_bytes, (\n",
    "                    output_json.get(\"crop_doc_height\", 0), output_json.get(\"crop_doc_width\", 0),\n",
    "                    output_json.get(\"crop_doc_channels\", 0))))).convert(\n",
    "                    \"RGBA\" if output_json.get(\"crop_doc_channels\", 0) == 4 else \"RGB\")\n",
    "            cropped_barcode_bytes = c_cropped_barcode[:c_cropped_barcode_len.value]\n",
    "            output_json[\"c_crop_barcode\"] = Image.fromarray(np.uint8(np.reshape(cropped_barcode_bytes, (\n",
    "                    output_json.get(\"crop_barcode_height\", 0), output_json.get(\"crop_barcode_width\", 0),\n",
    "                    output_json.get(\"crop_barcode_channels\", 0))))).convert(\n",
    "                    \"RGBA\" if output_json.get(\"crop_barcode_channels\", 0) == 4 else \"RGB\")\n",
    "            # The ouput_json contains `cropped_doc_width', 'cropped_doc_height` and `cropped_doc_channels` properties\n",
    "#             self._spl_so_face.FHE_free_api_memory(c_cropped_doc)\n",
    "\n",
    "            \n",
    "            # The ouput_json contains `cropped_barcode_width', 'cropped_barcode_height` and `cropped_barcode_channels` properties\n",
    "#             self._spl_so_face.FHE_free_api_memory(c_cropped_barcode)\n",
    "\n",
    "            \n",
    "            return output_json\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "    \n",
    "\n",
    "\n",
    "    def doc_scan_face(self, image_data: np.array, config_object = None) -> Any:\n",
    "        try:\n",
    "            img = image_data\n",
    "            im_width = img.shape[1]\n",
    "            im_height = img.shape[0]\n",
    "\n",
    "            p_buffer_images_in = img.flatten()\n",
    "            c_p_buffer_images_in = p_buffer_images_in.ctypes.data_as(POINTER(c_uint8))\n",
    "\n",
    "            c_result = c_char_p()\n",
    "            c_result_len = c_int()\n",
    "            c_cropped_doc = pointer(c_uint8())\n",
    "            c_cropped_doc_len = c_int()\n",
    "            c_cropped_face = pointer(c_uint8())\n",
    "            c_cropped_face_len = c_int()\n",
    "            if config_object and config_object.get_config_param():\n",
    "                c_config_param = c_char_p(bytes(config_object.get_config_param(), 'utf-8'))\n",
    "                c_config_param_len = c_int(len(config_object.get_config_param()))\n",
    "            else:\n",
    "                c_config_param = c_char_p(bytes(\"\", 'utf-8'))\n",
    "                c_config_param_len = c_int(0)\n",
    "            config_={\"document_face_check_validity\":True,\"document_face_predict\":True}\n",
    "\n",
    "            c_config_param = c_char_p(bytes(json.dumps(config_), 'utf-8'))\n",
    "            c_config_param_len = c_int(len(json.dumps(config_)))\n",
    "            print(\"config\",json.dumps(config_))\n",
    "            self._spl_so_face.privid_doc_scan_face(\n",
    "                self._spl_so_face.new_handle, c_config_param, c_config_param_len,\n",
    "                c_p_buffer_images_in, c_int(im_width), c_int(im_height),\n",
    "                byref(c_cropped_doc), byref(c_cropped_doc_len),\n",
    "                byref(c_cropped_face), byref(c_cropped_face_len),\n",
    "                byref(c_result), byref(c_result_len))\n",
    "\n",
    "            if not c_result.value or not c_result_len.value:\n",
    "                raise Exception(\"Something went wrong. Couldn't process the image for Document API. \")\n",
    "            output_json = c_result.value[:c_result_len.value].decode()\n",
    "            self._spl_so_face.FHE_free_api_memory(c_result)\n",
    "            \n",
    "            output_json = json.loads(output_json)\n",
    "            cropped_doc_bytes = c_cropped_doc[:c_cropped_doc_len.value]\n",
    "            output_json[\"c_crop_document\"] = Image.fromarray(np.uint8(np.reshape(cropped_doc_bytes, (\n",
    "                    output_json.get(\"cropped_doc_height\", 0), output_json.get(\"cropped_doc_width\", 0),\n",
    "                    output_json.get(\"cropped_doc_channels\", 0))))).convert(\n",
    "                    \"RGBA\" if output_json.get(\"crop_doc_channels\", 0) == 4 else \"RGB\")\n",
    "            cropped_face_bytes = c_cropped_face[:c_cropped_face_len.value]\n",
    "            try :\n",
    "                output_json[\"c_cropped_face\"] = Image.fromarray(np.uint8(np.reshape(cropped_face_bytes, (\n",
    "                    output_json.get(\"cropped_face_height\", 0), output_json.get(\"cropped_face_width\", 0),\n",
    "                    output_json.get(\"cropped_face_channels\", 0))))).convert(\n",
    "                    \"RGBA\" if output_json.get(\"cropped_face_channels\", 0) == 4 else \"RGB\")\n",
    "                return output_json\n",
    "            except:\n",
    "                return output_json\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e,)\n",
    "            return False\n",
    "        \n",
    "    def enroll(self, image_data: np.array,im_count:int,im_height, im_width, im_channel, config_object= None) -> Any:\n",
    "        try:\n",
    "            img_data = image_data\n",
    "\n",
    "            p_buffer_images_in = img_data.flatten()\n",
    "            c_p_buffer_images_in = p_buffer_images_in.ctypes.data_as(\n",
    "                POINTER(c_uint8))\n",
    "            im_size = im_height * im_width * im_channel\n",
    "            p_buffer_embeddings_out = np.zeros(\n",
    "                4 * self._embedding_length * self._num_embeddings, dtype=np.float32)\n",
    "            c_p_buffer_embeddings_out = p_buffer_embeddings_out.ctypes.data_as(\n",
    "                POINTER(c_float))\n",
    "            result_out = np.zeros(1, dtype=np.int32)\n",
    "            c_result_out = result_out.ctypes.data_as(POINTER(ctypes.c_int32))\n",
    "            c_result = c_char_p()\n",
    "            emb_out_length = np.zeros(1, dtype=np.int32)\n",
    "            c_emb_out_length = emb_out_length.ctypes.data_as(POINTER(ctypes.c_int32))\n",
    "\n",
    "            if config_object and config_object.get_config_param():\n",
    "                c_config_param = c_char_p(bytes(config_object.get_config_param(), 'utf-8'))\n",
    "                c_config_param_len = c_int(len(config_object.get_config_param()))\n",
    "            else:\n",
    "                c_config_param = c_char_p(bytes(\"\", 'utf-8'))\n",
    "                c_config_param_len = c_int(0)\n",
    "            self._spl_so_face.privid_enroll_onefa(self._spl_so_face.new_handle, c_config_param, c_config_param_len,\n",
    "                                                  c_p_buffer_images_in,\n",
    "                                                  c_int(im_count), c_int(im_size), c_int(im_width),\n",
    "                                                  c_int(im_height),\n",
    "                                                  c_p_buffer_embeddings_out, c_emb_out_length, c_bool(True),                                                  \n",
    "                                                  byref(c_result), c_result_out)\n",
    "\n",
    "            len_ = np.fromiter(c_result_out[:1], dtype=np.uint32, count=-1)[0]\n",
    "            output_json_str = c_result.value[:len_].decode()\n",
    "            self._spl_so_face.FHE_free_api_memory(byref(c_result))\n",
    "            if output_json_str is not None and len(output_json_str) > 0:\n",
    "                output = json.loads(output_json_str)\n",
    "                return output\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(\"Error :\", e)\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90584225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_path_to_array(image_path: str) -> np.ndarray:\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35adf9bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRIVID]:[2023-Mar-09 01:09:44]:[INFO]:[privid_main.cpp:257] Setting geometric thresholds\n",
      "\n",
      "[PRIVID]:[2023-Mar-09 01:09:44]:[DEBUG]:[privid_session.cpp:40] Already initialized constructor\n",
      "[PRIVID]:[2023-Mar-09 01:09:44]:[DEBUG]:[privid_session.cpp:42] Handler is already initialized\n",
      "[PRIVID]:[2023-Mar-09 01:09:44]:[INFO]:[privid_main.cpp:997]  param = 00000000000000001962, nParamLen = 20 len1 = 20\n",
      "\n",
      "[PRIVID]:[2023-Mar-09 01:09:44]:[INFO]:[privid_main.cpp:1013] API KEY 46 : id_conf_api_key  = \n",
      "\n",
      "[PRIVID]:[2023-Mar-09 01:09:44]:[INFO]:[privid_main.cpp:1015] Common URL 46 : id_conf_api_key  = 00000000000000001962\n",
      "\n",
      "[PRIVID]:[2023-Mar-09 01:09:44]:[INFO]:[privid_main.cpp:997]  param = https://api.devel.cryptonets.ai/node, nParamLen = 36 len1 = 36\n",
      "\n",
      "[PRIVID]:[2023-Mar-09 01:09:44]:[INFO]:[privid_main.cpp:1007] 42 : id_conf_url_endpoint_predict  = https://api.cryptonets.ai/node\n",
      "\n",
      "[PRIVID]:[2023-Mar-09 01:09:44]:[INFO]:[privid_main.cpp:1009] 42 : id_conf_url_endpoint_predict  = https://api.devel.cryptonets.ai/node\n",
      "\n"
     ]
    }
   ],
   "source": [
    "native_wrapper=NativeMethods(api_key=\"00000000000000001962\",server_url=\"https://api.devel.cryptonets.ai/node\",local_storage_path=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aba6c9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[privid_api_c.cpp:608] In doc_scan_barcode C Wrapper\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[privid_api_c.cpp:614] Creating doc_face object\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[op_doc_barcode.cpp:366] Registering barcode parsers\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[mat_utils.cpp:118] Creating cv::Mat\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[mat_utils.cpp:123] Input image is in RGB format\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[privid_api_c.cpp:627] Now scanning the back of the document\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:21] document_common::do_document_model.\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[0] out = [1373.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[1] out = [1844.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[2] out = [189.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[3] out = [1127.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[4] out = [2567.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[5] out = [1086.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[6] out = [2592.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[7] out = [2618.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[8] out = [213.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[9] out = [2644.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[10] out = [0.731423]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[11] out = [0.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:43] landmark[12] out = [0.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:127] Document Validation width ratio [0.786706] : height ratio [0.379960]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:58] Document Validation Result = [0]\n",
      "[PRIVID]:[2023-Mar-09 01:06:06]:[DEBUG]:[doc_common.cpp:60] Confidence Level = [0.731423]\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[face_utils.cpp:90] face_utils::is_blurry. Threshold [100.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[face_utils.cpp:99] Blur Test : Laplacian Variance = [341.834412] : Image Width [2378] : Height [1517]\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[face_utils.cpp:104] Image is not blur\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[doc_common.cpp:66] Document cropped image is good\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[op_doc_face.cpp:132] do_document_model status = [0]\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[op_doc_face.cpp:79] Validity tesing during document scan is not requested\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[op_doc_face.cpp:184] Face validity during document scan is not requested\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[op_doc_face.cpp:199] Face prediction during document scan is not requested\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[face_utils.cpp:90] face_utils::is_blurry. Threshold [4500.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[face_utils.cpp:99] Blur Test : Laplacian Variance = [16479.066406] : Image Width [224] : Height [224]\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[face_utils.cpp:104] Image is not blur\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[op_doc_barcode.cpp:330] Parsing barcode version >= 4\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[privid_api_c.cpp:629] Document barcode scan complete\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[privid_presentation.cpp:80] User Response in Presentation [{\"op_status\":0,\"op_message\":\"\",\"payload_type\":\"barcode\",\"barcode_conf_score\":0.966616153717041,\"barcode_c_x0\":1152.0,\"barcode_c_y0\":1288.0,\"barcode_x1\":512.0,\"barcode_y1\":1135.0,\"barcode_x2\":1797.0,\"barcode_y2\":1131.0,\"barcode_x3\":1799.0,\"barcode_y3\":1439.0,\"barcode_x4\":513.0,\"barcode_y4\":1444.0,\"crop_img_topleft_x\":460,\"crop_img_topleft_y\":1021,\"crop_img_botright_x\":1978,\"crop_img_botright_y\":1978,\"crop_doc_width\":2378,\"crop_doc_height\":1517,\"crop_doc_bytes\":10822278,\"crop_doc_channels\":3,\"crop_barcode_width\":1518,\"crop_barcode_height\":496,\"crop_barcode_bytes\":3011712,\"crop_barcode_channels\":4,\"type\":\"barcode\",\"format\":\"PDF417\",\"documentId\":\"3000DD7BE\",\"customerId\":\"P-463-603-189-192\",\"firstName\":\"MICHAEL\",\"lastName\":\"POLLARD\",\"middleName\":\"EDWARD\",\"expirationDate\":\"03132026\",\"issueDate\":\"05142019\",\"dateOfBirth\":\"03131968\",\"gender\":\"M\",\"eyeColor\":\"UNK\",\"hairColor\":\"\",\"height\":\"070 in\",\"streetAddress1\":\"13331 SIGNAL TREE LN\",\"streetAddress2\":\"\",\"RestStreetAddress1\":\"\",\"RestStreetAddress2\":\"\",\"city\":\"POTOMAC\",\"state\":\"MD\",\"postCode\":\"208540000  \",\"issuingCountry\":\"USA\",\"firstNameTruncation\":\"N\",\"placeOfBirth\":\"\",\"auditInformation\":\"\",\"inventoryControlNumber\":\"\",\"lastNameAlias\":\"\",\"firstNameAlias\":\"\",\"suffixAlias\":\"\",\"nameSuffix\":\"\",\"namePrefix\":\"\",\"barcode_key_string\":\"QAoeDUFOU0kgNjM2MDAzMDgwMDAyREwwMDQxMDI2MFpNMDMwMTAwMDhETERBUVAtNDYzLTYwMy0xODktMTkyCkRDU1BPTExBUkQKRERFTgpEQUNNSUNIQUVMCkRERk4KREFERURXQVJECkRER04KRENBQwpEQ0JCCkRDRE5PTkUKREJEMDUxNDIwMTkKREJCMDMxMzE5NjgKREJBMDMxMzIwMjYKREJDMQpEQVUwNzAgaW4KREFZVU5LCkRBRzEzMzMxIFNJR05BTCBUUkVFIExOCkRBSVBPVE9NQUMKREFKTUQKREFLMjA4NTQwMDAwICAKRENGMzAwMEREN0JFCkRDR1VTQQpEQ0sxMDAzNjExMjAwCkREQUYKRERCMDYyMDIwMTYKREFXMTcwDVpNWk1BMDEN\",\"barcode_key_string_encoding\":\"base64\",\"barcodeHash64_string\":\"14122558082321054754\",\"barcodeHash128_string\":\"519871973139070459512640627512685067234\"}]\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[privid_presentation.cpp:85] Copying operation response to user provided buffer. Response = [{\"op_status\":0,\"op_message\":\"\",\"payload_type\":\"barcode\",\"barcode_conf_score\":0.966616153717041,\"barcode_c_x0\":1152.0,\"barcode_c_y0\":1288.0,\"barcode_x1\":512.0,\"barcode_y1\":1135.0,\"barcode_x2\":1797.0,\"barcode_y2\":1131.0,\"barcode_x3\":1799.0,\"barcode_y3\":1439.0,\"barcode_x4\":513.0,\"barcode_y4\":1444.0,\"crop_img_topleft_x\":460,\"crop_img_topleft_y\":1021,\"crop_img_botright_x\":1978,\"crop_img_botright_y\":1978,\"crop_doc_width\":2378,\"crop_doc_height\":1517,\"crop_doc_bytes\":10822278,\"crop_doc_channels\":3,\"crop_barcode_width\":1518,\"crop_barcode_height\":496,\"crop_barcode_bytes\":3011712,\"crop_barcode_channels\":4,\"type\":\"barcode\",\"format\":\"PDF417\",\"documentId\":\"3000DD7BE\",\"customerId\":\"P-463-603-189-192\",\"firstName\":\"MICHAEL\",\"lastName\":\"POLLARD\",\"middleName\":\"EDWARD\",\"expirationDate\":\"03132026\",\"issueDate\":\"05142019\",\"dateOfBirth\":\"03131968\",\"gender\":\"M\",\"eyeColor\":\"UNK\",\"hairColor\":\"\",\"height\":\"070 in\",\"streetAddress1\":\"13331 SIGNAL TREE LN\",\"streetAddress2\":\"\",\"RestStreetAddress1\":\"\",\"RestStreetAddress2\":\"\",\"city\":\"POTOMAC\",\"state\":\"MD\",\"postCode\":\"208540000  \",\"issuingCountry\":\"USA\",\"firstNameTruncation\":\"N\",\"placeOfBirth\":\"\",\"auditInformation\":\"\",\"inventoryControlNumber\":\"\",\"lastNameAlias\":\"\",\"firstNameAlias\":\"\",\"suffixAlias\":\"\",\"nameSuffix\":\"\",\"namePrefix\":\"\",\"barcode_key_string\":\"QAoeDUFOU0kgNjM2MDAzMDgwMDAyREwwMDQxMDI2MFpNMDMwMTAwMDhETERBUVAtNDYzLTYwMy0xODktMTkyCkRDU1BPTExBUkQKRERFTgpEQUNNSUNIQUVMCkRERk4KREFERURXQVJECkRER04KRENBQwpEQ0JCCkRDRE5PTkUKREJEMDUxNDIwMTkKREJCMDMxMzE5NjgKREJBMDMxMzIwMjYKREJDMQpEQVUwNzAgaW4KREFZVU5LCkRBRzEzMzMxIFNJR05BTCBUUkVFIExOCkRBSVBPVE9NQUMKREFKTUQKREFLMjA4NTQwMDAwICAKRENGMzAwMEREN0JFCkRDR1VTQQpEQ0sxMDAzNjExMjAwCkREQUYKRERCMDYyMDIwMTYKREFXMTcwDVpNWk1BMDEN\",\"barcode_key_string_encoding\":\"base64\",\"barcodeHash64_string\":\"14122558082321054754\",\"barcodeHash128_string\":\"519871973139070459512640627512685067234\"}]\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[privid_presentation.cpp:88] Buffer length is greater than 0\n",
      "[PRIVID]:[2023-Mar-09 01:06:07]:[DEBUG]:[privid_presentation.cpp:102] Operation response copied to provided buffer\n",
      "{'op_status': 0, 'op_message': '', 'payload_type': 'barcode', 'barcode_conf_score': 0.966616153717041, 'barcode_c_x0': 1152.0, 'barcode_c_y0': 1288.0, 'barcode_x1': 512.0, 'barcode_y1': 1135.0, 'barcode_x2': 1797.0, 'barcode_y2': 1131.0, 'barcode_x3': 1799.0, 'barcode_y3': 1439.0, 'barcode_x4': 513.0, 'barcode_y4': 1444.0, 'crop_img_topleft_x': 460, 'crop_img_topleft_y': 1021, 'crop_img_botright_x': 1978, 'crop_img_botright_y': 1978, 'crop_doc_width': 2378, 'crop_doc_height': 1517, 'crop_doc_bytes': 10822278, 'crop_doc_channels': 3, 'crop_barcode_width': 1518, 'crop_barcode_height': 496, 'crop_barcode_bytes': 3011712, 'crop_barcode_channels': 4, 'type': 'barcode', 'format': 'PDF417', 'documentId': '3000DD7BE', 'customerId': 'P-463-603-189-192', 'firstName': 'MICHAEL', 'lastName': 'POLLARD', 'middleName': 'EDWARD', 'expirationDate': '03132026', 'issueDate': '05142019', 'dateOfBirth': '03131968', 'gender': 'M', 'eyeColor': 'UNK', 'hairColor': '', 'height': '070 in', 'streetAddress1': '13331 SIGNAL TREE LN', 'streetAddress2': '', 'RestStreetAddress1': '', 'RestStreetAddress2': '', 'city': 'POTOMAC', 'state': 'MD', 'postCode': '208540000  ', 'issuingCountry': 'USA', 'firstNameTruncation': 'N', 'placeOfBirth': '', 'auditInformation': '', 'inventoryControlNumber': '', 'lastNameAlias': '', 'firstNameAlias': '', 'suffixAlias': '', 'nameSuffix': '', 'namePrefix': '', 'barcode_key_string': 'QAoeDUFOU0kgNjM2MDAzMDgwMDAyREwwMDQxMDI2MFpNMDMwMTAwMDhETERBUVAtNDYzLTYwMy0xODktMTkyCkRDU1BPTExBUkQKRERFTgpEQUNNSUNIQUVMCkRERk4KREFERURXQVJECkRER04KRENBQwpEQ0JCCkRDRE5PTkUKREJEMDUxNDIwMTkKREJCMDMxMzE5NjgKREJBMDMxMzIwMjYKREJDMQpEQVUwNzAgaW4KREFZVU5LCkRBRzEzMzMxIFNJR05BTCBUUkVFIExOCkRBSVBPVE9NQUMKREFKTUQKREFLMjA4NTQwMDAwICAKRENGMzAwMEREN0JFCkRDR1VTQQpEQ0sxMDAzNjExMjAwCkREQUYKRERCMDYyMDIwMTYKREFXMTcwDVpNWk1BMDEN', 'barcode_key_string_encoding': 'base64', 'barcodeHash64_string': '14122558082321054754', 'barcodeHash128_string': '519871973139070459512640627512685067234', 'c_crop_document': <PIL.Image.Image image mode=RGB size=2378x1517 at 0x7F4E486080D0>, 'c_crop_barcode': <PIL.Image.Image image mode=RGBA size=1518x496 at 0x7F4E4860A560>}\n",
      "config {\"document_face_check_validity\": true, \"document_face_predict\": true}\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_api_c.cpp:561] In doc_scan_face C Wrapper\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_api_c.cpp:567] Creating doc_face object\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[mat_utils.cpp:118] Creating cv::Mat\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[mat_utils.cpp:123] Input image is in RGB format\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_api_c.cpp:580] Now scanning the document\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:21] document_common::do_document_model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:30575): EOG-CRITICAL **: 01:06:09.011: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:30575): GLib-GIO-CRITICAL **: 01:06:09.011: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[0] out = [1435.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[1] out = [1658.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[2] out = [217.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[3] out = [928.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[4] out = [2637.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[5] out = [913.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[6] out = [2641.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[7] out = [2405.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[8] out = [225.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[9] out = [2388.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[10] out = [0.972057]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[11] out = [0.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:43] landmark[12] out = [0.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:127] Document Validation width ratio [0.800265] : height ratio [0.370040]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:58] Document Validation Result = [0]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:60] Confidence Level = [0.972057]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:90] face_utils::is_blurry. Threshold [50.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:99] Blur Test : Laplacian Variance = [126.200134] : Image Width [2420] : Height [1460]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:104] Image is not blur\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[doc_common.cpp:66] Document cropped image is good\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_doc_face.cpp:132] do_document_model status = [0]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_valid.cpp:56] valid::process inputImage.width [1210] : inputImage.height [1460]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_valid.cpp:16] updating image format configuration for internal use\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:138] -------> face_utils::check_geometry_and_crop isContextEnroll [0] : width [1210] : height [1460]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:210] face_utils::check_geometry_and_crop ret = [0]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:217] result[24] = [0.986580] : config.GetConfScoreThreshold = [0.120000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[INFO]:[face_utils.cpp:259] CROP_WITH_EYE_ALIGN Enabled. confidenceIndex = 24\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:658] face_utils::crop_with_aligned_eyes\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:690] Calculated oFaceInfo.re_cx [515.500000] : oFaceInfo.re_cy [708.500000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:292] \n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:586] Setting face detection results. imageSize [1210] : conf_score [0.986580] : Status [0] : faceCount [1] : faceCount_nms [1] : orientation [0]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_valid.cpp:81] face_utils::check_geometry_and_crop result [0]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_valid.cpp:90] Blur Threshold for Enroll/Predict = [10.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:90] face_utils::is_blurry. Threshold [10.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:99] Blur Test : Laplacian Variance = [220.163986] : Image Width [224] : Height [224]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:104] Image is not blur\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_doc_face.cpp:95] Image is valid\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_valid.cpp:56] valid::process inputImage.width [1210] : inputImage.height [1460]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_valid.cpp:16] updating image format configuration for internal use\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:138] -------> face_utils::check_geometry_and_crop isContextEnroll [0] : width [1210] : height [1460]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:210] face_utils::check_geometry_and_crop ret = [0]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:217] result[24] = [0.986580] : config.GetConfScoreThreshold = [0.120000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[INFO]:[face_utils.cpp:259] CROP_WITH_EYE_ALIGN Enabled. confidenceIndex = 24\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:658] face_utils::crop_with_aligned_eyes\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:690] Calculated oFaceInfo.re_cx [515.500000] : oFaceInfo.re_cy [708.500000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:292] \n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:586] Setting face detection results. imageSize [1210] : conf_score [0.986580] : Status [0] : faceCount [1] : faceCount_nms [1] : orientation [0]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_valid.cpp:81] face_utils::check_geometry_and_crop result [0]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_valid.cpp:90] Blur Threshold for Enroll/Predict = [10.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:90] face_utils::is_blurry. Threshold [10.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:99] Blur Test : Laplacian Variance = [220.163986] : Image Width [224] : Height [224]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[face_utils.cpp:104] Image is not blur\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_doc_face.cpp:95] Image is valid\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_doc_face.cpp:174] Face validity performed. Face is valid\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_doc_face.cpp:192] Performing face prediction requested during document scan\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_session.cpp:76] Creating new transaction\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_session.cpp:78] Acquired session lock\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_session.cpp:83] New transaction created [2]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[mat_utils.cpp:118] Creating cv::Mat\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[mat_utils.cpp:123] Input image is in RGB format\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_predict.cpp:56] [PREDICT CONFIG] : PIN = [] : Identifier = []\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_predict.cpp:59] [API]: valid::process\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_faces.cpp:106] Detected 0 faces\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[op_predict.cpp:65] Face verification failed for predict\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_presentation.cpp:80] User Response in Presentation [{\"payload_type\":\"face_id\",\"doc_center_x\":1435.0,\"doc_center_y\":1658.0,\"doc_x1\":217.0,\"doc_y1\":928.0,\"doc_x2\":2637.0,\"doc_y2\":913.0,\"doc_x3\":2641.0,\"doc_y3\":2405.0,\"doc_x4\":225.0,\"doc_y4\":2388.0,\"conf_level\":0.9720568060874939,\"cropped_doc_width\":2420,\"cropped_doc_height\":1460,\"cropped_doc_channels\":3,\"doc_validation_status\":0,\"uuid\":\"\",\"guid\":\"\",\"predict_message\":\"Invalid Image\",\"face_validity_message\":\"Valid face\",\"op_message\":\"Success\",\"predict_status\":-100,\"enroll_level\":0,\"face_valid\":1,\"op_status\":0,\"cropped_face_width\":0,\"cropped_face_height\":0,\"cropped_face_size\":0,\"cropped_face_channels\":0}]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_presentation.cpp:85] Copying operation response to user provided buffer. Response = [{\"payload_type\":\"face_id\",\"doc_center_x\":1435.0,\"doc_center_y\":1658.0,\"doc_x1\":217.0,\"doc_y1\":928.0,\"doc_x2\":2637.0,\"doc_y2\":913.0,\"doc_x3\":2641.0,\"doc_y3\":2405.0,\"doc_x4\":225.0,\"doc_y4\":2388.0,\"conf_level\":0.9720568060874939,\"cropped_doc_width\":2420,\"cropped_doc_height\":1460,\"cropped_doc_channels\":3,\"doc_validation_status\":0,\"uuid\":\"\",\"guid\":\"\",\"predict_message\":\"Invalid Image\",\"face_validity_message\":\"Valid face\",\"op_message\":\"Success\",\"predict_status\":-100,\"enroll_level\":0,\"face_valid\":1,\"op_status\":0,\"cropped_face_width\":0,\"cropped_face_height\":0,\"cropped_face_size\":0,\"cropped_face_channels\":0}]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_presentation.cpp:88] Buffer length is greater than 0\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_presentation.cpp:102] Operation response copied to provided buffer\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_presentation.cpp:80] User Response in Presentation [{\"payload_type\":\"face_id\",\"doc_center_x\":1435.0,\"doc_center_y\":1658.0,\"doc_x1\":217.0,\"doc_y1\":928.0,\"doc_x2\":2637.0,\"doc_y2\":913.0,\"doc_x3\":2641.0,\"doc_y3\":2405.0,\"doc_x4\":225.0,\"doc_y4\":2388.0,\"conf_level\":0.9720568060874939,\"cropped_doc_width\":2420,\"cropped_doc_height\":1460,\"cropped_doc_channels\":3,\"doc_validation_status\":0,\"uuid\":\"\",\"guid\":\"\",\"predict_message\":\"\",\"face_validity_message\":\"Valid face\",\"op_message\":\"Success\",\"predict_status\":-1,\"enroll_level\":0,\"face_valid\":1,\"op_status\":0,\"cropped_face_width\":0,\"cropped_face_height\":0,\"cropped_face_size\":0,\"cropped_face_channels\":0}]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_presentation.cpp:85] Copying operation response to user provided buffer. Response = [{\"payload_type\":\"face_id\",\"doc_center_x\":1435.0,\"doc_center_y\":1658.0,\"doc_x1\":217.0,\"doc_y1\":928.0,\"doc_x2\":2637.0,\"doc_y2\":913.0,\"doc_x3\":2641.0,\"doc_y3\":2405.0,\"doc_x4\":225.0,\"doc_y4\":2388.0,\"conf_level\":0.9720568060874939,\"cropped_doc_width\":2420,\"cropped_doc_height\":1460,\"cropped_doc_channels\":3,\"doc_validation_status\":0,\"uuid\":\"\",\"guid\":\"\",\"predict_message\":\"\",\"face_validity_message\":\"Valid face\",\"op_message\":\"Success\",\"predict_status\":-1,\"enroll_level\":0,\"face_valid\":1,\"op_status\":0,\"cropped_face_width\":0,\"cropped_face_height\":0,\"cropped_face_size\":0,\"cropped_face_channels\":0}]\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_presentation.cpp:88] Buffer length is greater than 0\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_presentation.cpp:102] Operation response copied to provided buffer\n",
      "[PRIVID]:[2023-Mar-09 01:06:09]:[DEBUG]:[privid_api_c.cpp:583] Document scan complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'payload_type': 'face_id', 'doc_center_x': 1435.0, 'doc_center_y': 1658.0, 'doc_x1': 217.0, 'doc_y1': 928.0, 'doc_x2': 2637.0, 'doc_y2': 913.0, 'doc_x3': 2641.0, 'doc_y3': 2405.0, 'doc_x4': 225.0, 'doc_y4': 2388.0, 'conf_level': 0.9720568060874939, 'cropped_doc_width': 2420, 'cropped_doc_height': 1460, 'cropped_doc_channels': 3, 'doc_validation_status': 0, 'uuid': '', 'guid': '', 'predict_message': '', 'face_validity_message': 'Valid face', 'op_message': 'Success', 'predict_status': -1, 'enroll_level': 0, 'face_valid': 1, 'op_status': 0, 'cropped_face_width': 0, 'cropped_face_height': 0, 'cropped_face_size': 0, 'cropped_face_channels': 0, 'c_crop_document': <PIL.Image.Image image mode=RGB size=2420x1460 at 0x7F4E4860A320>}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'c_cropped_face'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m doc_scan_face[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_crop_document\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(doc_scan_face)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdoc_scan_face\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc_cropped_face\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'c_cropped_face'"
     ]
    }
   ],
   "source": [
    "doc_scan_barcode_=native_wrapper.doc_scan_barcode(image_data=image_path_to_array('./back.jpg'))\n",
    "doc_scan_barcode_[\"c_crop_document\"].show()\n",
    "doc_scan_barcode_[\"c_crop_barcode\"].show()\n",
    "print(doc_scan_barcode_)\n",
    "doc_scan_face=native_wrapper.doc_scan_face(image_data=image_path_to_array('./front.jpg'))\n",
    "doc_scan_face[\"c_crop_document\"].show()\n",
    "print(doc_scan_face)\n",
    "doc_scan_face[\"c_cropped_face\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff49765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ae0e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1=image_path_to_array(\"/home/azam/projects/openinfer/python sdk/public/cryptonets-python-sdk/tests/enroll_images/enroll_images/laptop/5rn476o17944r8qq9pn7_ 2ps9r38p0n037orq0045_1.jpeg\")\n",
    "image_2=image_path_to_array(\"/home/azam/projects/openinfer/python sdk/public/cryptonets-python-sdk/tests/enroll_images/enroll_images/laptop/5rn476o17944r8qq9pn7_ 2ps9r38p0n037orq0045_3.jpeg\")\n",
    "image_3=image_path_to_array(\"/home/azam/projects/openinfer/python sdk/public/cryptonets-python-sdk/tests/enroll_images/enroll_images/laptop/5rn476o17944r8qq9pn7_ 2ps9r38p0n037orq0045.jpeg\")\n",
    "stack_image=np.vstack((image_2,image_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6633d8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRIVID]:[2023-Mar-09 01:09:49]:[DEBUG]:[privid_api_c.cpp:363] In enroll_onefa C Wrapper\n",
      "[PRIVID]:[2023-Mar-09 01:09:49]:[DEBUG]:[privid_billing.cpp:40] Adding API Key member\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[privid_api_c.cpp:373] Loading configuration object\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[privid_api_c.cpp:383] Copying image to vector\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[privid_api_c.cpp:385] Running Enroll\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[privid_session.cpp:76] Creating new transaction\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[privid_session.cpp:78] Acquired session lock\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[privid_session.cpp:83] New transaction created [2]\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[mat_utils.cpp:118] Creating cv::Mat\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[mat_utils.cpp:123] Input image is in RGB format\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[mat_utils.cpp:118] Creating cv::Mat\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[mat_utils.cpp:123] Input image is in RGB format\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_enroll.cpp:50] [PREDICT CONFIG] : PIN = [] : Identifier = []\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_enroll.cpp:55] [API]: valid::process\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_faces.cpp:106] Detected 1 faces\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[utils_common.cpp:29] Landmarks: [4] = 0.355653, [10] = 0.494673, [8] = 0.620852, [24] = 0.936743\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[utils_common.cpp:75] Calculated oFaceInfo.re_cx [709.000000] : oFaceInfo.re_cy [400.000000]\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_valid.cpp:32] ----------> Actual Validation Status = [0]\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_faces.cpp:106] Detected 1 faces\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[utils_common.cpp:29] Landmarks: [4] = 0.421565, [10] = 0.565789, [8] = 0.668794, [24] = 0.993814\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[utils_common.cpp:75] Calculated oFaceInfo.re_cx [789.500000] : oFaceInfo.re_cy [407.500000]\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_valid.cpp:32] ----------> Actual Validation Status = [0]\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_enroll.cpp:69] Face verification successful for enroll\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_enroll.cpp:70] Computing Augmentations\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_enroll.cpp:75] Finding Embeddings\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_common.cpp:39] Finding embeddings\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_common.cpp:72] Embeddings loop done\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_enroll.cpp:80] Embeddings Found\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_enroll.cpp:85] Copying embeddings to output\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_enroll.cpp:94] Embeddings_out.size() = [7680]\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_common.cpp:17] Creating embeddings json\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_common.cpp:22] Embeddings json created\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_enroll.cpp:99] Getting enroll/predict response from server\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_enroll.cpp:202] Calling Rest API to gen 1FA Response\n",
      "[PRIVID]:[2023-Mar-09 01:09:50]:[DEBUG]:[op_enroll.cpp:208] Enroll 1FA Endpoint = [https://api.devel.cryptonets.ai/node/enroll]\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[op_enroll.cpp:231] ID = [2] : API Response = [{\"PI\":{\"enroll_level\":1,\"factor\":\"face\",\"guid\":\"0ca5a6a92625cd6482c7eebd0d83061ce0b43a6a482735b197e7c1c3f69848864230303030303138366332626362383634\",\"uuid\":\"0c61fddd8d9fce853f883c3d9e3e352c47aea155f2426bf0866f1c2cfcba2e1bcf30303030303138366332626362383634\"},\"message\":\"Person exists. Skipping enroll.\",\"status\":0}]\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[privid_helpers.cpp:209] Token Json      = [{\"uuid\":\"o12620nr4r4q8rn8q238\",\"enroll_level\":1,\"timestamp\":1678284593}]\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[privid_helpers.cpp:210] Token Encrypted = [09539420E6800ABCA25836F28390346FD37DCB0CC1EC7D79364CDB210B3A3A78DCAAC0CAF729FB9133BC31132C15A62872402D469CD06A15F884E83658A9FF916821FEBBF24C101DB4341F0AA4DB526DDA30303030303138366332626362386339]\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[privid_helpers.cpp:271] Copying data to user buffer helper\n",
      "\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[privid_helpers.cpp:273] Encrypted Timestamped Response = [{\"PI\":{\"enroll_level\":1,\"factor\":\"face\",\"guid\":\"2ps9r38p0n037orq0045\",\"uuid\":\"o12620nr4r4q8rn8q238\"},\"message\":\"Person exists. Skipping enroll.\",\"status\":0,\"validation_status\":[{\"status\":0,\"conf_score\":0.936743438243866},{\"status\":0,\"conf_score\":0.9938137531280518}],\"token\":\"09539420E6800ABCA25836F28390346FD37DCB0CC1EC7D79364CDB210B3A3A78DCAAC0CAF729FB9133BC31132C15A62872402D469CD06A15F884E83658A9FF916821FEBBF24C101DB4341F0AA4DB526DDA30303030303138366332626362386339\"}]\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[privid_helpers.cpp:126] Copying data to provided buffer\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[privid_helpers.cpp:129] Buffer length is greater than 0\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[privid_helpers.cpp:145] Data copied to provided buffer\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[op_enroll.cpp:215] API Return Response = [1]\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[op_enroll.cpp:107] Synchronizing UUIDs\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[cache_factory.cpp:12] Creating nocache singleton\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[nocache.h:15] Initializing No Cache\n",
      "[PRIVID]:[2023-Mar-09 01:09:53]:[DEBUG]:[op_enroll.cpp:110] UUIDs synchronized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PI': {'enroll_level': 1,\n",
       "  'factor': 'face',\n",
       "  'guid': '2ps9r38p0n037orq0045',\n",
       "  'uuid': 'o12620nr4r4q8rn8q238'},\n",
       " 'message': 'Person exists. Skipping enroll.',\n",
       " 'status': 0,\n",
       " 'validation_status': [{'status': 0, 'conf_score': 0.936743438243866},\n",
       "  {'status': 0, 'conf_score': 0.9938137531280518}],\n",
       " 'token': '09539420E6800ABCA25836F28390346FD37DCB0CC1EC7D79364CDB210B3A3A78DCAAC0CAF729FB9133BC31132C15A62872402D469CD06A15F884E83658A9FF916821FEBBF24C101DB4341F0AA4DB526DDA30303030303138366332626362386339'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_height, im_width, im_channel=image_3.shape\n",
    "native_wrapper.enroll(image_data=stack_image,im_count=2,im_height=im_height, im_width=im_width, im_channel=im_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d98bcabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d202c46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573c54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
